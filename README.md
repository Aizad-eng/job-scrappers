# Job Scraper v2.0 - Config-Driven Architecture

**Adding a new scraper = Adding JSON config. Zero code changes. No migrations.**

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ACTOR REGISTRY (actor_registry.py)           â”‚
â”‚  Define actors with:                                            â”‚
â”‚  - Input schema (what the UI form shows)                        â”‚
â”‚  - Input template (how to build Apify payload)                  â”‚
â”‚  - Output mapping (how to extract standardized fields)          â”‚
â”‚  - Filter config (what can be filtered)                         â”‚
â”‚  - Clay template (what gets sent to webhook)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENERIC SERVICES                             â”‚
â”‚  - ApifyService: Builds payload from template, runs actor       â”‚
â”‚  - FilterService: Applies filters based on config               â”‚
â”‚  - ClayService: Transforms output using template                â”‚
â”‚  - ScraperService: Orchestrates the workflow                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Adding a New Actor (5 minutes)

### Step 1: Open `actor_registry.py`

### Step 2: Add your actor to `SEED_ACTORS`:

```python
SEED_ACTORS = {
    # ... existing actors ...
    
    "my_new_actor": {
        "display_name": "My New Job Scraper",
        "actor_id": "username~actor-name",  # From Apify
        "default_timeout_minutes": 15,
        "default_max_results": 100,
        
        # What inputs does the UI show?
        "input_schema": [
            {"name": "search_query", "type": "text", "label": "Search Query", "required": True},
            {"name": "location", "type": "text", "label": "Location", "default": "USA"},
            {"name": "max_results", "type": "number", "label": "Max Results", "default": 100},
        ],
        
        # How to build the Apify input payload
        "input_template": {
            "query": "{{search_query}}",
            "location": "{{location}}",
            "maxItems": "{{max_results}}"
        },
        
        # How to extract standardized fields from output
        "output_mapping": {
            "job_id": "id",
            "title": "jobTitle",
            "company_name": "company.name",
            "location": "location",
            "description": "description",
            "job_url": "url"
        },
        
        # What can be filtered?
        "filter_config": {
            "company_name_excludes": {"field": "company.name", "type": "exclude_contains"},
            "min_employees": {"field": "company.size", "type": "min_value"},
            "max_employees": {"field": "company.size", "type": "max_value"}
        },
        
        # What gets sent to Clay?
        "clay_template": {
            "ID": "{{job_id}}",
            "Job Title": "{{title}}",
            "Company": "{{company_name}}",
            "Location": "{{location}}",
            "Description": "{{description}}",
            "URL": "{{job_url}}"
        }
    }
}
```

### Step 3: Restart the app

That's it! The new actor will:
- Appear in the dropdown
- Generate dynamic form fields
- Work with filtering
- Send to Clay webhook

## Configuration Reference

### Input Schema Field Types

| Type | Description | Example |
|------|-------------|---------|
| `text` | Single line text | Search query |
| `textarea` | Multi-line text | URLs (one per line) |
| `url` | URL validation | Search URL |
| `number` | Numeric input | Max results |
| `boolean` | Checkbox | Enable feature |
| `select` | Dropdown | Time range |

### Input Schema Field Properties

```python
{
    "name": "field_name",        # Internal name
    "type": "text",              # Field type
    "label": "Display Label",    # UI label
    "required": True,            # Required?
    "default": "value",          # Default value
    "placeholder": "hint",       # Placeholder text
    "help": "Help text",         # Help text below field
    "options": [                 # For select type only
        {"value": "a", "label": "Option A"},
        {"value": "b", "label": "Option B"}
    ]
}
```

### Template Variables

In `input_template` and `clay_template`, use `{{variable_name}}` to reference:
- Actor inputs from the form
- Extracted fields from output mapping

**Special suffix `_array`**: Converts newline/comma text to array
```python
"titleSearch": "{{title_search_array}}"  # "a\nb\nc" -> ["a", "b", "c"]
```

### Output Mapping - Nested Fields

Use dot notation for nested fields:
```python
"output_mapping": {
    "company_name": "company.name",           # data["company"]["name"]
    "first_location": "locations[0]",         # data["locations"][0]
    "deep_field": "a.b[0].c.d"               # Complex nesting
}
```

### Filter Types

| Type | Description | Example Use |
|------|-------------|-------------|
| `exclude_contains` | Exclude if field contains any value | Company name blacklist |
| `include_contains` | Include only if field contains value | Industry whitelist |
| `min_value` | Exclude if field < value | Min employees |
| `max_value` | Exclude if field > value | Max employees |
| `equals` | Exclude if field != value | Exact match |
| `not_equals` | Exclude if field == value | Exclude exact value |

## File Structure

```
job-scraper-v2/
â”œâ”€â”€ main.py              # FastAPI app & endpoints
â”œâ”€â”€ models.py            # SQLAlchemy models
â”œâ”€â”€ schemas.py           # Pydantic schemas
â”œâ”€â”€ database.py          # Database config
â”œâ”€â”€ actor_registry.py    # ðŸ‘ˆ ADD NEW ACTORS HERE
â”œâ”€â”€ template_engine.py   # Variable substitution
â”œâ”€â”€ apify_service.py     # Generic Apify client
â”œâ”€â”€ filter_service.py    # Generic filtering
â”œâ”€â”€ clay_service.py      # Generic Clay webhook
â”œâ”€â”€ scraper_service.py   # Orchestrator
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html       # Dynamic UI
â””â”€â”€ requirements.txt
```

## Deployment

### Environment Variables

```bash
DATABASE_URL=postgresql://user:pass@host:5432/dbname
APIFY_API_TOKEN=your_token
```

### Render Deployment

1. Push to GitHub
2. Create new Web Service on Render
3. Set environment variables
4. Deploy!

Database tables are created automatically on startup.

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/actors` | List all actors |
| GET | `/api/actors/{key}/input-schema` | Get actor's form schema |
| GET | `/api/searches` | List job searches |
| POST | `/api/searches` | Create job search |
| PUT | `/api/searches/{id}` | Update job search |
| DELETE | `/api/searches/{id}` | Delete job search |
| POST | `/api/searches/{id}/execute` | Run immediately |
| POST | `/api/searches/{id}/duplicate` | Duplicate search |
| GET | `/api/searches/{id}/runs` | Get run history |
| POST | `/api/test-actor` | Test actor config |

## Migration from v1

If you have existing data from v1, you'll need to:

1. Export your job search configurations
2. Deploy v2 (creates new schema)
3. Recreate searches via UI or API

The new schema is fundamentally different (dynamic JSON vs fixed columns), so direct migration isn't possible.

## Troubleshooting

### Actor not showing up?
- Check the actor_key is unique
- Restart the app (actors are seeded on startup)

### Fields not extracting correctly?
- Check output_mapping paths match the actual Apify output
- Use the test endpoint to preview raw data

### Filters not working?
- Check filter_config field paths are correct
- Ensure filter_rules in job search match filter_config keys
